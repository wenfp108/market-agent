name: Daily Heatmap & JSON Report

on:
  schedule:
    - cron: '30 15 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build-report:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Generate Reports
        run: |
          cat <<'EOF' > analyzer.py
          import os
          import json
          
          # === 1. æ™ºèƒ½æŸ¥æ‰¾æœ€æ–°æ•°æ®æ–‡ä»¶å¤¹ ===
          data_root = "data"
          if not os.path.exists(data_root):
              print("é”™è¯¯: data ç›®å½•ä¸å­˜åœ¨")
              exit(0)
          
          # è·å– data ä¸‹æ‰€æœ‰çš„æ—¥æœŸæ–‡ä»¶å¤¹ï¼Œå¹¶æŒ‰åç§°æ’åº
          all_dirs = [d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d)) and d[0].isdigit()]
          all_dirs.sort()
          
          if not all_dirs:
              print("é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ—¥æœŸæ•°æ®æ–‡ä»¶å¤¹")
              exit(0)
              
          # é”å®šæœ€æ–°çš„ä¸€ä¸ªæ–‡ä»¶å¤¹ (ä¸ç®¡ä»Šå¤©æ˜¯å‡ å·ï¼Œåªæ‹¿æœ€æ–°çš„)
          latest_date = all_dirs[-1] 
          source_dir = os.path.join(data_root, latest_date)
          
          # === 2. è®¾å®šè¾“å‡ºç›®å½• ===
          report_dir = "reports"
          if not os.path.exists(report_dir):
              os.makedirs(report_dir)

          print(f"ğŸ¯ é”å®šæœ€æ–°æ•°æ®æº: {source_dir}")

          # === 3. æ ¸å¿ƒèšåˆé€»è¾‘ ===
          event_map = {}
          file_count = 0

          for filename in os.listdir(source_dir):
              if filename.endswith(".json"):
                  file_count += 1
                  filepath = os.path.join(source_dir, filename)
                  try:
                      with open(filepath, 'r') as f:
                          content = json.load(f)
                          
                          meta = content.get('meta', {})
                          data = content.get('data', {})
                          event_id = meta.get('id', data.get('slug', 'unknown'))
                          
                          if event_id not in event_map:
                              event_map[event_id] = {
                                  "count": 0,
                                  "latest_data": content 
                              }
                          
                          event_map[event_id]["count"] += 1
                          
                          current_vol = float(data.get('volume', 0))
                          saved_vol = float(event_map[event_id]['latest_data'].get('data', {}).get('volume', 0))
                          
                          if current_vol > saved_vol:
                              event_map[event_id]['latest_data'] = content

                  except Exception as e:
                      print(f"Error reading {filename}: {e}")

          # === å‡†å¤‡æ•°æ® ===
          report_list = []
          raw_data_list = []

          for eid, info in event_map.items():
              raw_data = info['latest_data']
              raw_data_list.append(raw_data)

              data = raw_data.get('data', {})
              meta = raw_data.get('meta', {})
              
              top_outcome = "N/A"
              top_prob = 0
              if 'markets' in data and len(data['markets']) > 0:
                  m = data['markets'][0]
                  try:
                      prices = json.loads(m.get('outcomePrices', '[]'))
                      outcomes = json.loads(m.get('outcomes', '[]'))
                      if prices and outcomes:
                          max_p = max(prices)
                          idx = prices.index(max_p)
                          top_outcome = outcomes[idx]
                          top_prob = float(max_p) * 100
                  except:
                      pass

              report_list.append({
                  "title": meta.get('title', data.get('title', eid)),
                  "sector": meta.get('sector_tag', 'General'),
                  "count": info['count'],
                  "volume": float(data.get('volume', 0)),
                  "prob_str": f"{top_outcome} ({top_prob:.1f}%)",
                  "url": f"https://polymarket.com/event/{eid}"
              })

          report_list.sort(key=lambda x: (x['count'], x['volume']), reverse=True)

          # === è¾“å‡º 1: Markdown ===
          # æ³¨æ„ï¼šæ–‡ä»¶åä½¿ç”¨æ•°æ®æºçš„æ—¥æœŸï¼Œä¿æŒä¸€è‡´
          md = f"# ğŸ“Š å…¨å¤©å€™çƒ­åŠ›æˆ˜æŠ¥ ({latest_date})\n\n"
          md += f"**æ•°æ®æº**: `{latest_date}` | **æ–‡ä»¶é‡‡æ ·**: {file_count} | **å»é‡äº‹ä»¶**: {len(report_list)}\n\n"
          md += "| çƒ­åº¦ | æ¿å— | äº‹ä»¶æ ‡é¢˜ | å…±è¯† | èµ„é‡‘ |\n"
          md += "| :--- | :--- | :--- | :--- | :--- |\n"

          for item in report_list:
              count = item['count']
              if count >= 20: icon = "ğŸ”¥ğŸ”¥ğŸ”¥"
              elif count >= 10: icon = "ğŸ”¥"
              elif count >= 5: icon = "â­ï¸"
              else: icon = "â„ï¸"
              vol = f"${item['volume']/1000000:.2f}M" if item['volume'] > 1000000 else f"${item['volume']/1000:.0f}k"
              md += f"| {icon} {count} | {item['sector']} | [{item['title']}]({item['url']}) | {item['prob_str']} | {vol} |\n"

          with open(f"{report_dir}/DAILY_HEATMAP_{latest_date}.md", "w") as f:
              f.write(md)

          # === è¾“å‡º 2: JSON Summary ===
          json_path = f"{report_dir}/DAILY_SUMMARY_{latest_date}.json"
          with open(json_path, 'w') as f:
              json.dump(raw_data_list, f, indent=2)

          print(f"âœ… æˆåŠŸ! æŠ¥è¡¨å·²ç”Ÿæˆåœ¨ reports/ ç›®å½•ï¼ŒåŸºäº {latest_date} æ•°æ®")
          EOF

          python analyzer.py

      - name: Commit results
        run: |
          git config --global user.name "Report Bot"
          git config --global user.email "bot@github.com"
          git add reports/
          git commit -m "ğŸ“Š Generate Reports" || exit 0
          git push
